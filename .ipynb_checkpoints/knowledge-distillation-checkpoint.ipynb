{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "lV1P1qv7m51q",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luigi-doria/IC/Data_sets/cifar-10-python.tar.gz\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python.tar.gz\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.03.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.82.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.02.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.92.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.97.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.51.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.87.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.14.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.15.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.24.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.25.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.27.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_77.35.pth\n",
      "/home/luigi-doria/IC/Data_sets/Redes_Treinadas/Restnet18_acc_94.66.pth\n",
      "/home/luigi-doria/IC/Data_sets/Redes_Treinadas/vgg11_acc_91.98.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net9.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net10.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net8.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net6.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net3.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net1.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net4.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net12.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net11.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net2.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net5.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net13.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net7.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net14.pth\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/file.txt~\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/meta\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/test\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/train\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_5\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_1\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_2\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_3\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/batches.meta\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/readme.html\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_4\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/test_batch\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/12 Redes/Metodo 2/Temp 3/student3_acc_95.34.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/12 Redes/Metodo 1/Temp 2/student_acc_93.18.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/13 Redes/Metodo 2/Temp 3/student3_acc_93.8.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/13 Redes/Metodo 1/Temp 2/student_acc_93.21.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/6 Redes/Metodo 2/Temp 3/student3_acc_95.4.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/6 Redes/Metodo 1/Temp 2/student_acc_93.05.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/9 Redes/Metodo 2/Temp 3/student3_acc_95.41.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/9 Redes/Metodo 1/Temp 2/student_acc_93.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/8 Redes/Metodo 2/Temp 3/student3_acc_95.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/8 Redes/Metodo 1/Temp 2/student_acc_93.17.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/7 Redes/Metodo 2/Temp 3/student3_acc_95.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/7 Redes/Metodo 1/Temp 2/student_acc_93.25.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/2 Redes/Metodo 2/Temp 3/student3_acc_95.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/2 Redes/Metodo 2/Temp 3/student4_acc_93.21.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/2 Redes/Metodo 1/Temp 2/student_acc_93.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/2 Redes/Metodo 1/Temp 2/student2_acc_91.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/3 Redes/Metodo 2/Temp 3/student3_acc_95.43.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/3 Redes/Metodo 1/Temp 2/student_acc_93.09.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/3 Redes/Metodo 1/Temp 2/student2_acc_90.64.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/15 Redes/Metodo 2/Temp 3/student4_acc_93.18.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/15 Redes/Metodo 2/Temp 3/student3_acc_95.4.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/15 Redes/Metodo 1/Temp 2/student2_acc_90.81.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/15 Redes/Metodo 1/Temp 2/student_acc_93.35.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/11 Redes/Metodo 2/Temp 3/student3_acc_95.31.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/11 Redes/Metodo 2/Temp 3/student4_acc_93.13.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/11 Redes/Metodo 1/Temp 2/student_acc_93.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/11 Redes/Metodo 1/Temp 2/student2_acc_90.38.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/20 Redes/Metodo 2/Temp 3/student4_acc_93.35.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/20 Redes/Metodo 2/Temp 3/student3_acc_93.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/20 Redes/Metodo 1/Temp 2/student2_acc_93.09.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/20 Redes/Metodo 1/Temp 2/student_acc_93.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/14 Redes/Metodo 2/Temp 3/student3_acc_95.54.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/14 Redes/Metodo 1/Temp 2/student_acc_93.31.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/5 Redes/Metodo 2/Temp 3/student3_acc_95.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/5 Redes/Metodo 1/Temp 2/student_acc_93.0.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/10 Redes/Metodo 2/Temp 3/student3_acc_93.62.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/10 Redes/Metodo 1/Temp 2/student_acc_93.26.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/4 Redes/Metodo 2/Temp 3/student3_acc_95.47.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble cifar10/4 Redes/Metodo 1/Temp 2/student_acc_93.28.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/luigi-doria/IC/Data_sets'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zohB14ssm51s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# LIBRARYs\n",
    "#import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import argparse\n",
    "import itertools\n",
    "from sklearn.metrics import roc_curve as ROC\n",
    "\n",
    "from sklearn.metrics import auc,brier_score_loss\n",
    "from torch.optim import Adam\n",
    "print(torch.__version__)\n",
    "\n",
    "from Utils.data_set import *\n",
    "from Utils.loading import *\n",
    "from Utils.treino import *\n",
    "from Utils.init_redes import *\n",
    "from Utils.ensemble import *\n",
    "from Utils.redes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeINEJb2m51s",
    "outputId": "cb366b04-9678-492d-93b8-6a9f84c628fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'  \n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6rwVfpBm51u",
    "outputId": "f5b5068a-ff1b-44f9-fc3a-36fe2aa1be62",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loading Nets\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "n_nets = 15\n",
    "\n",
    "data_set = \"Cifar10\"\n",
    "\n",
    "if data_set == \"Cifar10\":\n",
    "    transform_train, transform_test, batch_size, trainset, trainloader, testset, testloader, classes = cifar10()\n",
    "    print(\"Loading Nets\")\n",
    "    nets = load_cifar10(n_nets)\n",
    "    print(\"End\")\n",
    "elif data_set == \"Cifar100\":\n",
    "    transform_train, transform_test, batch_size, trainset, trainloader, testset, testloader= cifar100()\n",
    "    print(\"Loading Nets\")\n",
    "    nets = load_cifar100(n_nets)\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8AAFG8_m51v"
   },
   "source": [
    "# Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RQp9G3YPm51x",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.21%\n"
     ]
    }
   ],
   "source": [
    "teacher = DeepEnsemble(nets[0:3], apply_softmax=True)\n",
    "acuracia = testa_acuracia(teacher,testloader)\n",
    "print(f'Accuracy of the network on the {len(testloader.dataset)} test images: {acuracia}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlC72VMIm51z"
   },
   "source": [
    "#  Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Tfu_lOfUm51z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "student , loss_criterion , optimizer_student , scheduler_student  = init_rede_all(\"Resnet\")\n",
    "student3, loss_criterion3, optimizer_student3, scheduler_student3 = init_rede_all(\"Resnet\")\n",
    "#student4, loss_criterion4, optimizer_student4, scheduler_student4 = init_rede_all(\"Resnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNL9CKWYm51z",
    "tags": []
   },
   "source": [
    "# Primeiro metodo baseado no artigo: Distilling the Knowledge in a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2lMP9G-am51z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hparamToString(hparam):\n",
    "    \"\"\"\n",
    "    Convert hparam dictionary to string with deterministic order of attribute of hparam in output string\n",
    "    \"\"\"\n",
    "    hparam_str = ''\n",
    "    for k, v in sorted(hparam.items()):\n",
    "        hparam_str += k + '=' + str(v) + ', '\n",
    "    return hparam_str[:-2]\n",
    "\n",
    "def hparamDictToTuple(hparam):\n",
    "    \"\"\"\n",
    "    Convert hparam dictionary to tuple with deterministic order of attribute of hparam in output tuple\n",
    "    \"\"\"\n",
    "    hparam_tuple = [v for k, v in sorted(hparam.items())]\n",
    "    return tuple(hparam_tuple)\n",
    "\n",
    "def studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha):\n",
    "    \"\"\"\n",
    "    One training step of student network: forward prop + backprop + update parameters\n",
    "    Return: (loss, accuracy) of current batch\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    teacher_pred = None\n",
    "    if (alpha > 0):\n",
    "        with torch.no_grad():\n",
    "            teacher_pred = teacher_net(X)\n",
    "    student_pred = student_net(X)\n",
    "    loss = studentLossFn(teacher_pred, student_pred, y, T, alpha, teacher_net)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = float(torch.sum(torch.argmax(student_pred, dim=1) == y).item()) / y.shape[0]\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, name,\n",
    "    train_loader, val_loader, \n",
    "    print_every=0, \n",
    "    fast_device=torch.device('cuda')):\n",
    "    \"\"\"\n",
    "    Trains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch\n",
    "    Return: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
    "    \"\"\"\n",
    "    teacher_net.eval()\n",
    "    train_loss_list, train_acc_list, val_acc_list = [], [], []\n",
    "    T = hparam['T']\n",
    "    alpha = hparam['alpha']\n",
    "    student_net.dropout_input = hparam['dropout_input']\n",
    "    student_net.dropout_hidden = hparam['dropout_hidden']\n",
    "    optimizer = optim.SGD(student_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
    "\n",
    "    def studentLossFn(teacher_pred, student_pred, y, T, alpha,teacher_net):\n",
    "        \"\"\"\n",
    "        Loss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
    "        Return: loss\n",
    "        \"\"\"\n",
    "        if (alpha > 0):\n",
    "            if str(type(teacher_net)) == \"<class '__main__.DeepEnsemble'>\":\n",
    "                loss = F.kl_div(F.log_softmax(student_pred / T, dim=1), teacher_pred, reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "            else:\n",
    "                loss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1), reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "        else:\n",
    "            loss = F.cross_entropy(student_pred, y)\n",
    "        return loss\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == 0:\n",
    "            if val_loader is not None:\n",
    "                _, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
    "                val_acc_list.append(val_acc)\n",
    "                print('epoch: %d validation accuracy: %.3f' %(epoch, val_acc))\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            X, y = data\n",
    "            X, y = X.to(fast_device), y.to(fast_device)\n",
    "            loss, acc = studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha)\n",
    "            train_loss_list.append(loss)\n",
    "            train_acc_list.append(acc)               \n",
    "            if print_every > 0 and i % print_every == print_every - 1:\n",
    "                if acc > best_acc:\n",
    "                    best_acc_ = acc\n",
    "                print('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f best train accuracy: %.3f' %\n",
    "                (epoch + 1, i + 1, len(train_loader), loss, acc, best_acc_))\n",
    "        lr_scheduler.step()\n",
    "        if acc > best_acc:\n",
    "            torch.save(student_net.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "        if acc == best_acc:\n",
    "            if loss < best_loss:\n",
    "                torch.save(student_net.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "                best_loss = loss\n",
    "        \n",
    "        if val_loader is not None:\n",
    "            _, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
    "            val_acc_list.append(val_acc)\n",
    "            print('epoch: %d validation accuracy: %.3f' %(epoch + 1, val_acc))\n",
    "    return {'train_loss': train_loss_list, \n",
    "            'train_acc': train_acc_list, \n",
    "            'val_acc': val_acc_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2-9ECYlm510",
    "tags": []
   },
   "source": [
    "# Segundo metodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9LFVt5ERm510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "softmax_op = nn.Softmax(dim=1)\n",
    "mseloss_fn = nn.MSELoss()\n",
    "def my_loss(scores, targets, target,temperature = 5):\n",
    "    soft_pred = softmax_op(scores / temperature)\n",
    "    with torch.no_grad():\n",
    "        if str(type(target)) == \"<class '__main__.DeepEnsemble'>\":\n",
    "            soft_targets = targets\n",
    "        else:\n",
    "            soft_targets = softmax_op(targets / temperature)\n",
    "    loss = mseloss_fn(soft_pred, soft_targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I070FU2Mm510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature):\n",
    "    aprendiz.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    target.eval()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "        scores = aprendiz(images)\n",
    "        with torch.no_grad():\n",
    "            targets = target(images.to(\"cuda\"))\n",
    "        loss = my_loss(scores, targets, target,temperature)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = scores.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.to(device)).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    acc = 100.*correct/total\n",
    "\n",
    "    return train_loss, acc\n",
    "        \n",
    "def test_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature, best_acc, best_loss,name):\n",
    "    aprendiz.eval()\n",
    "    target.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = aprendiz(inputs)\n",
    "            targets = target(inputs)\n",
    "            loss = loss_criterion(outputs, targets, target,temperature)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        #print('Saving..')\n",
    "        torch.save(aprendiz.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "        best_acc = acc\n",
    "        best_loss = test_loss\n",
    "    if acc == best_acc:\n",
    "        if loss < best_loss:\n",
    "            torch.save(aprendiz.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "            best_loss = test_loss\n",
    "    return test_loss, acc, best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Grk-WKbum510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature, best_acc, best_loss, name):\n",
    "    loss_train, acc_train = train_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature)\n",
    "    loss_test , acc_test, best_acc, best_loss  = test_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature, best_acc, best_loss,name)\n",
    "    print(\"Loss Train: {} || Acc Train: {} || Loss Teste: {} || Acc Teste: {} || Best Acc Teste: {}\".format(loss_train, acc_train, loss_test, acc_test, best_acc))\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6l7IoQ3Em511",
    "outputId": "647f9b32-5ab0-417c-bde1-a387e4474c16",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_redes = 3\n",
    "temperatures = [2]\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "alphas = [0.5]\n",
    "learning_rates = [1e-2]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-5]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "\n",
    "teacher = DeepEnsemble(nets[0:n_redes], temperatura=temperatures[0])\n",
    "\n",
    "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                        momentums, learning_rates):\n",
    "    hparam = {}\n",
    "    hparam['alpha'] = hparam_tuple[0]\n",
    "    hparam['T'] = hparam_tuple[1]\n",
    "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "    hparam['weight_decay'] = hparam_tuple[3]\n",
    "    hparam['lr_decay'] = hparam_tuple[4]\n",
    "    hparam['momentum'] = hparam_tuple[5]\n",
    "    hparam['lr'] = hparam_tuple[6]\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "\n",
    "for hparam in hparams_list:\n",
    "    #break\n",
    "    print('Training with hparams' + hparamToString(hparam))\n",
    "    hparam_tuple = hparamDictToTuple(hparam)\n",
    "    print(\"Student: \")\n",
    "    print()\n",
    "    results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net=teacher, student_net=student, hparam=hparam, num_epochs=100, \n",
    "                                                                train_loader=trainloader, val_loader=None, \n",
    "                                                                print_every=391, name=\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upwzKFatm511"
   },
   "outputs": [],
   "source": [
    "n_redes = 3\n",
    "temperatura = 3\n",
    "\n",
    "best_acc3 = 0\n",
    "best_loss3 = 0\n",
    "\n",
    "teacher2 = DeepEnsemble(nets[0:n_redes], temperatura=temperatura)\n",
    "for epoch in range(start_epoch, 100):\n",
    "    #break\n",
    "    print(\"Epoca: \",epoch)\n",
    "    print(\"Student 3: \", end=\" \")\n",
    "    best_acc3, best_loss3 = knowledge_distillation(epoch, aprendiz=student3 , loss_criterion=my_loss, optimizer=optimizer_student3 , scheduler=scheduler_student3 ,target=teacher2, temperature=temperatura, best_acc=best_acc3, best_loss=best_loss3, name=\"3\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5IMrNpZPm511",
    "outputId": "ede5fbbd-11b4-4898-b7a6-38d1fc917744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Student  on the 10000 test images: 71.76 %\n",
      "Accuracy of the Student3 on the 10000 test images: 1.2 %\n"
     ]
    }
   ],
   "source": [
    "# Calcula a acuracia da rede\n",
    "\n",
    "student, _,__,___  = init_rede_all(\"Resnet100\")\n",
    "student3, _,__,___  = init_rede_all(\"Resnet100\")\n",
    "\n",
    "student.load_state_dict(torch.load(\"/home/luigi-doria/IC/Resultado_parciais/student_acc.pth\"))\n",
    "student3.load_state_dict(torch.load(\"/home/luigi-doria/IC/Resultado_parciais/student3_acc.pth\"))\n",
    "\n",
    "student.eval()\n",
    "student3.eval()\n",
    "\n",
    "correct = 0\n",
    "correct3 = 0\n",
    "\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    \n",
    "    student.eval()\n",
    "    student3.eval()\n",
    "    \n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = student(images)\n",
    "        outputs = outputs.to(\"cpu\")\n",
    "\n",
    "        outputs3 = student3(images)\n",
    "        outputs3 = outputs3.to(\"cpu\")\n",
    "\n",
    "        outputs_numpy = outputs.to(\"cpu\").numpy()\n",
    "        outputs_numpy3 = outputs3.to(\"cpu\").numpy()\n",
    "\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, predicted3 = torch.max(outputs3.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct3 += (predicted3 == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the Student  on the {len(testloader.dataset)} test images: {round(100 * correct / total,3)} %')\n",
    "print(f'Accuracy of the Student3 on the {len(testloader.dataset)} test images: {round(100 * correct3 / total,3)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zNfEUcCPm511"
   },
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), ('/home/luigi-doria/IC/Resultados_Finais/student_acc_{}.pth').format(round(100 * correct / total,3)))\n",
    "torch.save(student3.state_dict(), ('/home/luigi-doria/IC/Resultados_Finais/student3_acc_{}.pth').format(round(100 * correct3 / total,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "365df4e071874a41a26e9b8db43c1060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39818c11a2cf4477963f0243032c1511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dadb8a25a0694c00b889e0fb1d9ef1f6",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4ad2c93af7a4e22868ec0b38e6dc47a",
      "value": 170498071
     }
    },
    "3fd1a23fdcaa4e61aed97bfedd46ce5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49946b9e2a294d6692e550a699d614c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c0d146e4d054275ac5eae9eb029f1f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d769d9b865f64d6aa2c1d14adc54a816",
       "IPY_MODEL_39818c11a2cf4477963f0243032c1511",
       "IPY_MODEL_b052db7575c74b6190814bbd137b5464"
      ],
      "layout": "IPY_MODEL_3fd1a23fdcaa4e61aed97bfedd46ce5e"
     }
    },
    "b052db7575c74b6190814bbd137b5464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49946b9e2a294d6692e550a699d614c1",
      "placeholder": "​",
      "style": "IPY_MODEL_365df4e071874a41a26e9b8db43c1060",
      "value": " 170498071/170498071 [00:03&lt;00:00, 54603965.71it/s]"
     }
    },
    "b4ad2c93af7a4e22868ec0b38e6dc47a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b96b3740fb82456e90e50521d8c2e2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d769d9b865f64d6aa2c1d14adc54a816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e74138fa3ce148c9b0de8e8ec5d5959a",
      "placeholder": "​",
      "style": "IPY_MODEL_b96b3740fb82456e90e50521d8c2e2f0",
      "value": "100%"
     }
    },
    "dadb8a25a0694c00b889e0fb1d9ef1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e74138fa3ce148c9b0de8e8ec5d5959a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
