{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "lV1P1qv7m51q",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luigi-doria/IC/Data_sets/cifar-10-python.tar.gz\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python.tar.gz\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.03.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.82.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.02.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.92.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.97.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.51.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_75.87.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.14.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.15.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.24.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.25.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_76.27.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar100/Restnet18_acc_77.35.pth\n",
      "/home/luigi-doria/IC/Data_sets/Redes_Treinadas/Restnet18_acc_94.66.pth\n",
      "/home/luigi-doria/IC/Data_sets/Redes_Treinadas/vgg11_acc_91.98.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net9.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net10.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net8.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net6.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net3.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net1.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net4.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net12.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net11.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net2.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net5.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net13.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net7.pth\n",
      "/home/luigi-doria/IC/Data_sets/Cifar10/net14.pth\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/file.txt~\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/meta\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/test\n",
      "/home/luigi-doria/IC/Data_sets/cifar-100-python/train\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_5\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_1\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_2\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_3\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/batches.meta\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/readme.html\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/data_batch_4\n",
      "/home/luigi-doria/IC/Data_sets/cifar-10-batches-py/test_batch\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/6 Redes/Metodo 2/Temp 3/student3_acc_74.38.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/6 Redes/Metodo 1/Temp 2/student_acc_74.38.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/2 Redes/Metodo 2/Temp 3/student_acc_74.06.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/2 Redes/Metodo 2/Temp 3/student3_acc_76.34.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/2 Redes/Metodo 1/Temp 2/student_acc_74.06.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/3 Redes/Metodo 2/Temp 3/student3_acc_76.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/3 Redes/Metodo 1/Temp 2/student_acc_71.76.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/15 Redes/Metodo 2/Temp 3/student3_acc_76.87.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/15 Redes/Metodo 1/Temp 2/student_acc_74.64.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/5 Redes/Metodo 2/Temp 3/student3_acc_74.36.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/5 Redes/Metodo 1/Temp 2/student_acc_74.36.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/5 Redes/Metodo 1/Temp 4/student_acc_75.94.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/4 Redes/Metodo 2/Temp 3/student3_acc_74.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar100/4 Redes/Metodo 1/Temp 2/student_acc_74.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 10/student_acc_75.98.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 10/student3_acc_11.44.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 1/student_acc_71.83.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 1/student3_acc_75.77.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 6/student_acc_75.99.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 6/student3_acc_16.73.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 5/student3_acc_20.79.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 5/student_acc_75.8.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 2/student_acc_74.48.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 2/student3_acc_77.06.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 9/student_acc_75.94.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 9/student3_acc_10.97.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 4/student3_acc_57.29.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 4/student_acc_76.02.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 3/student3_acc_76.61.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 3/student_acc_75.82.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 7/student3_acc_14.99.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 7/student_acc_75.82.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 8/student_acc_76.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/Cifar100/Temp 8/student3_acc_14.21.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/12 Redes/Metodo 2/Temp 3/student3_acc_95.34.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/12 Redes/Metodo 1/Temp 2/student_acc_93.18.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/13 Redes/Metodo 2/Temp 3/student3_acc_93.8.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/13 Redes/Metodo 1/Temp 2/student_acc_93.21.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/6 Redes/Metodo 2/Temp 3/student3_acc_95.4.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/6 Redes/Metodo 1/Temp 2/student_acc_93.05.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/9 Redes/Metodo 2/Temp 3/student3_acc_95.41.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/9 Redes/Metodo 1/Temp 2/student_acc_93.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/8 Redes/Metodo 2/Temp 3/student3_acc_95.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/8 Redes/Metodo 1/Temp 2/student_acc_93.17.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/7 Redes/Metodo 2/Temp 3/student3_acc_95.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/7 Redes/Metodo 1/Temp 2/student_acc_93.25.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/2 Redes/Metodo 2/Temp 3/student3_acc_95.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/2 Redes/Metodo 2/Temp 3/student4_acc_93.21.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/2 Redes/Metodo 1/Temp 2/student_acc_93.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/2 Redes/Metodo 1/Temp 2/student2_acc_91.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/3 Redes/Metodo 2/Temp 3/student3_acc_95.43.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/3 Redes/Metodo 1/Temp 2/student_acc_93.09.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/3 Redes/Metodo 1/Temp 2/student2_acc_90.64.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/15 Redes/Metodo 2/Temp 3/student4_acc_93.18.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/15 Redes/Metodo 2/Temp 3/student3_acc_95.4.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/15 Redes/Metodo 1/Temp 2/student2_acc_90.81.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/15 Redes/Metodo 1/Temp 2/student_acc_93.35.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/11 Redes/Metodo 2/Temp 3/student3_acc_95.31.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/11 Redes/Metodo 2/Temp 3/student4_acc_93.13.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/11 Redes/Metodo 1/Temp 2/student_acc_93.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/11 Redes/Metodo 1/Temp 2/student2_acc_90.38.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/20 Redes/Metodo 2/Temp 3/student4_acc_93.35.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/20 Redes/Metodo 2/Temp 3/student3_acc_93.19.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/20 Redes/Metodo 1/Temp 2/student2_acc_93.09.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/20 Redes/Metodo 1/Temp 2/student_acc_93.04.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/14 Redes/Metodo 2/Temp 3/student3_acc_95.54.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/14 Redes/Metodo 1/Temp 2/student_acc_93.31.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/5 Redes/Metodo 2/Temp 3/student3_acc_95.37.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/5 Redes/Metodo 1/Temp 2/student_acc_93.0.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/10 Redes/Metodo 2/Temp 3/student3_acc_93.62.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/10 Redes/Metodo 1/Temp 2/student_acc_93.26.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/4 Redes/Metodo 2/Temp 3/student3_acc_95.47.pth\n",
      "/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble Cifar10/4 Redes/Metodo 1/Temp 2/student_acc_93.28.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/luigi-doria/IC/Data_sets'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zohB14ssm51s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# LIBRARYs\n",
    "#import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import argparse\n",
    "import itertools\n",
    "from sklearn.metrics import roc_curve as ROC\n",
    "\n",
    "from sklearn.metrics import auc,brier_score_loss\n",
    "from torch.optim import Adam\n",
    "print(torch.__version__)\n",
    "\n",
    "from Utils.data_set import *\n",
    "from Utils.loading import *\n",
    "from Utils.treino import *\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeINEJb2m51s",
    "outputId": "cb366b04-9678-492d-93b8-6a9f84c628fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'  \n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "6c0d146e4d054275ac5eae9eb029f1f9",
      "d769d9b865f64d6aa2c1d14adc54a816",
      "39818c11a2cf4477963f0243032c1511",
      "b052db7575c74b6190814bbd137b5464",
      "3fd1a23fdcaa4e61aed97bfedd46ce5e",
      "e74138fa3ce148c9b0de8e8ec5d5959a",
      "b96b3740fb82456e90e50521d8c2e2f0",
      "dadb8a25a0694c00b889e0fb1d9ef1f6",
      "b4ad2c93af7a4e22868ec0b38e6dc47a",
      "49946b9e2a294d6692e550a699d614c1",
      "365df4e071874a41a26e9b8db43c1060"
     ]
    },
    "id": "Z-Mq00Z2m51t",
    "outputId": "64d66061-a373-46ba-b763-524a859a1a39",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_set = \"Cifar100\"\n",
    "\n",
    "if data_set == \"Cifar10\":\n",
    "    transform_train, transform_test, batch_size, trainset, trainloader, testset, testloader, classes = cifar10()\n",
    "elif data_set == \"Cifar100\":\n",
    "    transform_train, transform_test, batch_size, trainset, trainloader, testset, testloader= cifar100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def ResNet18_100():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NN5bQN1fm51t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESrEDkqXm51u",
    "outputId": "66eb422c-ff63-4de3-90a4-36f851578359",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Define o criterion e o optimizer\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "#if device == 'cuda':\n",
    "#    net = torch.nn.DataParallel(net)\n",
    "#    cudnn.benchmark = True\n",
    "\n",
    "print(device)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.2,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UEDz03hNm51u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_nets(n_nets):\n",
    "    nets = list()\n",
    "    for i in range(n_nets):\n",
    "        if i == 0:\n",
    "            i = \"\"\n",
    "        print(i)        \n",
    "        net_0 = torch.load(\"/home/luigi-doria/IC/Data_sets/Cifar10/net{}.pth\".format(i)).module.to(\"cuda\")\n",
    "        net_teste2 = ResNet18().to(\"cuda\")\n",
    "        net_teste2.load_state_dict(net_0.state_dict())\n",
    "        net_teste2.eval()\n",
    "        nets.append(net_teste2)    \n",
    "    return nets\n",
    "\n",
    "\n",
    "def caculate_outputs(nets, images):\n",
    "    outputs = list()\n",
    "    for i in range(len(nets)):\n",
    "        outputs.append(nets[i](images))\n",
    "    return outputs\n",
    "\n",
    "def calculate_correct(predicted, labels):\n",
    "    correct_aux = (predicted == labels.to(\"cuda\")).sum().item()\n",
    "    return round(1-correct_aux/10000,4)\n",
    "\n",
    "def calculate_predicted(mean_list):\n",
    "    uncs_max, predicted_aux = torch.max(mean_list.data, 1)\n",
    "    uncs_var = torch.var(mean_list,1)\n",
    "    uncs_entr = torch.special.entr(mean_list)\n",
    "    uncs_sum_entr = -torch.sum(uncs_entr, dim=-1)\n",
    "    return uncs_max, uncs_var, uncs_sum_entr, predicted_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6rwVfpBm51u",
    "outputId": "f5b5068a-ff1b-44f9-fc3a-36fe2aa1be62",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Nets\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "n_nets = 15\n",
    "print(\"Loading Nets\")\n",
    "#nets = load_nets(n_nets)\n",
    "nets = load_cifar100(n_nets)\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8AAFG8_m51v",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ejk7Qiezm51v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.ensemble = self.get_samples(x)\n",
    "        mean = torch.mean(self.ensemble,axis = 0)\n",
    "        return mean\n",
    "\n",
    "class DeepEnsemble(Ensemble):\n",
    "    def __init__(self,models, apply_softmax:bool = True, temperatura:int = 1):\n",
    "        super().__init__(models)\n",
    "        self.model = torch.nn.ParameterList()\n",
    "        for m in models:\n",
    "            self.model.append(m)\n",
    "        self.apply_softmax = apply_softmax\n",
    "        self.temperatura = temperatura\n",
    "    \n",
    "    def get_samples(self,x):\n",
    "        ensemble = []\n",
    "        for model in self.model:\n",
    "            pred = model(x)\n",
    "            pred /= self.temperatura\n",
    "            if self.apply_softmax:\n",
    "                pred = nn.functional.softmax(pred,dim=-1)\n",
    "            ensemble.append(pred)\n",
    "        self.ensemble = torch.stack(ensemble)\n",
    "        return self.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXHuLpEWm51x"
   },
   "source": [
    "# Criando uma rede menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "f3wwHPyQm51x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IykfZ4fgm51x"
   },
   "source": [
    "# Inicializando as redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "i_NBN5zHm51x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_rede(nome):\n",
    "    if nome == \"Resnet\":\n",
    "        student = ResNet18()\n",
    "    elif nome == \"VGG11\":\n",
    "        student = VGG('VGG11')\n",
    "    elif nome == \"Resnet100\":\n",
    "        student = ResNet18_100()\n",
    "\n",
    "    student = student.to(device)\n",
    "    if device == 'cuda':\n",
    "        student = torch.nn.DataParallel(student)\n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_student = optim.SGD(student.parameters(), lr=0.2,\n",
    "                          momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler_student = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_student, T_max=200)\n",
    "    \n",
    "    return student, loss_criterion, optimizer_student, scheduler_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LB56iZkpm51y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testa_acuracia(student, testloader=testloader):\n",
    "    # Calcula a acuracia da rede\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    student.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            #break\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = student(images.to(\"cuda\"))\n",
    "            outputs = outputs.to(\"cpu\")\n",
    "            outputs_numpy = outputs.to(\"cpu\").numpy()\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acuracia = round(100 * correct / total,3)\n",
    "    return acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "RQp9G3YPm51x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#teacher = DeepEnsemble(nets[0:3], apply_softmax=True)\n",
    "#acuracia = testa_acuracia(teacher)\n",
    "#print(f'Accuracy of the network on the {len(testloader.dataset)} test images: {acuracia}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlC72VMIm51z"
   },
   "source": [
    "#  Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Tfu_lOfUm51z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "student , loss_criterion , optimizer_student , scheduler_student  = init_rede(\"Resnet100\")\n",
    "#student2, loss_criterion2, optimizer_student2, scheduler_student2 = init_rede(\"VGG11\" )\n",
    "student3, loss_criterion3, optimizer_student3, scheduler_student3 = init_rede(\"Resnet100\")\n",
    "#student4, loss_criterion4, optimizer_student4, scheduler_student4 = init_rede(\"VGG11\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNL9CKWYm51z"
   },
   "source": [
    "# Primeiro metodo baseado no artigo: Distilling the Knowledge in a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "2lMP9G-am51z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hparamToString(hparam):\n",
    "    \"\"\"\n",
    "    Convert hparam dictionary to string with deterministic order of attribute of hparam in output string\n",
    "    \"\"\"\n",
    "    hparam_str = ''\n",
    "    for k, v in sorted(hparam.items()):\n",
    "        hparam_str += k + '=' + str(v) + ', '\n",
    "    return hparam_str[:-2]\n",
    "\n",
    "def hparamDictToTuple(hparam):\n",
    "    \"\"\"\n",
    "    Convert hparam dictionary to tuple with deterministic order of attribute of hparam in output tuple\n",
    "    \"\"\"\n",
    "    hparam_tuple = [v for k, v in sorted(hparam.items())]\n",
    "    return tuple(hparam_tuple)\n",
    "\n",
    "def studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha):\n",
    "    \"\"\"\n",
    "    One training step of student network: forward prop + backprop + update parameters\n",
    "    Return: (loss, accuracy) of current batch\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    teacher_pred = None\n",
    "    if (alpha > 0):\n",
    "        with torch.no_grad():\n",
    "            teacher_pred = teacher_net(X)\n",
    "    student_pred = student_net(X)\n",
    "    loss = studentLossFn(teacher_pred, student_pred, y, T, alpha, teacher_net)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = float(torch.sum(torch.argmax(student_pred, dim=1) == y).item()) / y.shape[0]\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, name,\n",
    "    train_loader, val_loader, \n",
    "    print_every=0, \n",
    "    fast_device=torch.device('cuda')):\n",
    "    \"\"\"\n",
    "    Trains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch\n",
    "    Return: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
    "    \"\"\"\n",
    "    teacher_net.eval()\n",
    "    train_loss_list, train_acc_list, val_acc_list = [], [], []\n",
    "    T = hparam['T']\n",
    "    alpha = hparam['alpha']\n",
    "    student_net.dropout_input = hparam['dropout_input']\n",
    "    student_net.dropout_hidden = hparam['dropout_hidden']\n",
    "    optimizer = optim.SGD(student_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
    "\n",
    "    def studentLossFn(teacher_pred, student_pred, y, T, alpha,teacher_net):\n",
    "        \"\"\"\n",
    "        Loss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
    "        Return: loss\n",
    "        \"\"\"\n",
    "        if (alpha > 0):\n",
    "            if isinstance(teacher_net,DeepEnsemble):\n",
    "                loss = F.kl_div(F.log_softmax(student_pred / T, dim=1), teacher_pred, reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "            else:\n",
    "                loss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1), reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "        else:\n",
    "            loss = F.cross_entropy(student_pred, y)\n",
    "        return loss\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        student_net.train()\n",
    "        if epoch == 0:\n",
    "            if val_loader is not None:\n",
    "                _, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
    "                val_acc_list.append(val_acc)\n",
    "                print('epoch: %d validation accuracy: %.3f' %(epoch, val_acc))\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            X, y = data\n",
    "            X, y = X.to(fast_device), y.to(fast_device)\n",
    "            loss, acc = studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha)\n",
    "            train_loss_list.append(loss)\n",
    "            train_acc_list.append(acc)               \n",
    "            if print_every > 0 and i % print_every == print_every - 1:\n",
    "                acc_teste = testa_acuracia(student_net)\n",
    "                print('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f test accuracy: %.3f' %\n",
    "                (epoch + 1, i + 1, len(train_loader), loss, acc,acc_teste))\n",
    "                \n",
    "                wandb.log({\"epoch\": epoch, \"loss\": loss, \"acuracia treino\": acc*100, \"acuracia teste\": acc_teste})\n",
    "        lr_scheduler.step()\n",
    "        if acc > best_acc:\n",
    "            torch.save(student_net.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "        if acc == best_acc:\n",
    "            if loss < best_loss:\n",
    "                torch.save(student_net.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "                best_loss = loss\n",
    "        \n",
    "        if val_loader is not None:\n",
    "            _, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
    "            val_acc_list.append(val_acc)\n",
    "            print('epoch: %d validation accuracy: %.3f' %(epoch + 1, val_acc))\n",
    "    return {'train_loss': train_loss_list, \n",
    "            'train_acc': train_acc_list, \n",
    "            'val_acc': val_acc_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2-9ECYlm510"
   },
   "source": [
    "# Segundo metodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "9LFVt5ERm510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "softmax_op = nn.Softmax(dim=1)\n",
    "mseloss_fn = nn.MSELoss(reduction = 'none')\n",
    "def my_loss(scores, targets, target,temperature = 5):\n",
    "    #soft_pred = softmax_op(scores / temperature)\n",
    "    soft_pred = softmax_op(scores)\n",
    "    with torch.no_grad():\n",
    "        if isinstance(target,DeepEnsemble):\n",
    "            soft_targets = targets\n",
    "        else:\n",
    "            soft_targets = softmax_op(targets / temperature)\n",
    "    loss = mseloss_fn(soft_pred, soft_targets)\n",
    "    return loss.sum(-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "I070FU2Mm510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature):\n",
    "    aprendiz.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    target.eval()\n",
    "    aprendiz.to(\"cuda\")\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "        scores = aprendiz(images.to(\"cuda\"))\n",
    "        with torch.no_grad():\n",
    "            targets = target(images.to(\"cuda\"))\n",
    "        loss = loss_criterion(scores, targets, target,temperature)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = scores.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.to(device)).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    acc = 100.*correct/total\n",
    "\n",
    "    return train_loss, acc\n",
    "        \n",
    "def test_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature, best_acc, best_loss,name):\n",
    "    aprendiz.eval()\n",
    "    target.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    aprendiz.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = aprendiz(inputs)\n",
    "            targets = target(inputs)\n",
    "            loss = loss_criterion(outputs, targets, target,temperature)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        #print('Saving..')\n",
    "        torch.save(aprendiz.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "        best_acc = acc\n",
    "        best_loss = test_loss\n",
    "    if acc == best_acc:\n",
    "        if loss < best_loss:\n",
    "            torch.save(aprendiz.state_dict(), ('/home/luigi-doria/IC/Resultado_parciais/student{}_acc.pth').format(name))\n",
    "            best_loss = test_loss\n",
    "    return test_loss, acc, best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Grk-WKbum510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature, best_acc, best_loss, name):\n",
    "    loss_train, acc_train = train_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature)\n",
    "    loss_test , acc_test, best_acc, best_loss  = test_knowledge_distillation(epoch, aprendiz, loss_criterion, optimizer, scheduler,target, temperature, best_acc, best_loss,name)\n",
    "    print(\"Loss Train: {} || Acc Train: {} || Loss Teste: {} || Acc Teste: {} || Best Acc Teste: {}\".format(loss_train, acc_train, loss_test, acc_test, best_acc))\n",
    "    return loss_train, acc_train, acc_test,best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6l7IoQ3Em511",
    "outputId": "647f9b32-5ab0-417c-bde1-a387e4474c16",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/luigi-doria/IC/wandb/run-20230303_230337-o78za5x9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/luigidoria/knowledge%20distillation%20Cifar100/runs/o78za5x9\" target=\"_blank\">Ensemble 14</a></strong> to <a href=\"https://wandb.ai/luigidoria/knowledge%20distillation%20Cifar100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/luigidoria/knowledge%20distillation%20Cifar100\" target=\"_blank\">https://wandb.ai/luigidoria/knowledge%20distillation%20Cifar100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/luigidoria/knowledge%20distillation%20Cifar100/runs/o78za5x9\" target=\"_blank\">https://wandb.ai/luigidoria/knowledge%20distillation%20Cifar100/runs/o78za5x9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=4, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n",
      "Student: \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 48\u001b[0m results_distill[hparam_tuple] \u001b[38;5;241m=\u001b[39m \u001b[43mtrainStudentOnHparam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m391\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     52\u001b[0m student_final, _,__,___  \u001b[38;5;241m=\u001b[39m init_rede(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResnet100\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m student_final\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/luigi-doria/IC/Resultado_parciais/student_acc.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[15], line 78\u001b[0m, in \u001b[0;36mtrainStudentOnHparam\u001b[0;34m(teacher_net, student_net, hparam, num_epochs, name, train_loader, val_loader, print_every, fast_device)\u001b[0m\n\u001b[1;32m     76\u001b[0m X, y \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     77\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(fast_device), y\u001b[38;5;241m.\u001b[39mto(fast_device)\n\u001b[0;32m---> 78\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mstudentTrainStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudentLossFn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     80\u001b[0m train_acc_list\u001b[38;5;241m.\u001b[39mappend(acc)               \n",
      "Cell \u001b[0;32mIn[15], line 31\u001b[0m, in \u001b[0;36mstudentTrainStep\u001b[0;34m(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha)\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m/\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, accuracy\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2,16):\n",
    "    student , loss_criterion , optimizer_student , scheduler_student  = init_rede(\"Resnet100\")\n",
    "    config = dict (\n",
    "      architecture = \"Resnet18\",\n",
    "      N_ensemble = \"{}\".format(i),\n",
    "      Data_set = \"Cifar 100\",\n",
    "      temperatura = 4,\n",
    "    )\n",
    "    \n",
    "    wandb.init(project=\"knowledge distillation Cifar100\", config=config, name=\"Ensemble {}\".format(i), group=\"KL_DIV\")\n",
    "        \n",
    "    n_redes = i\n",
    "    temperatures = [4]\n",
    "    # trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "    # loss = alpha * st + (1 - alpha) * tt\n",
    "    alphas = [0.5]\n",
    "    learning_rates = [1e-2]\n",
    "    learning_rate_decays = [0.95]\n",
    "    weight_decays = [1e-5]\n",
    "    momentums = [0.9]\n",
    "    dropout_probabilities = [(0.0, 0.0)]\n",
    "    hparams_list = []\n",
    "\n",
    "    teacher = DeepEnsemble(nets[0:n_redes], temperatura=temperatures[0])\n",
    "\n",
    "    for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
    "                                            momentums, learning_rates):\n",
    "        hparam = {}\n",
    "        hparam['alpha'] = hparam_tuple[0]\n",
    "        hparam['T'] = hparam_tuple[1]\n",
    "        hparam['dropout_input'] = hparam_tuple[2][0]\n",
    "        hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
    "        hparam['weight_decay'] = hparam_tuple[3]\n",
    "        hparam['lr_decay'] = hparam_tuple[4]\n",
    "        hparam['momentum'] = hparam_tuple[5]\n",
    "        hparam['lr'] = hparam_tuple[6]\n",
    "        hparams_list.append(hparam)\n",
    "\n",
    "    results_distill = {}\n",
    "\n",
    "    for hparam in hparams_list:\n",
    "        #break\n",
    "        print('Training with hparams' + hparamToString(hparam))\n",
    "        hparam_tuple = hparamDictToTuple(hparam)\n",
    "        print(\"Student: \")\n",
    "        print()\n",
    "        results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net=teacher, student_net=student, hparam=hparam, num_epochs=100, \n",
    "                                                                    train_loader=trainloader, val_loader=None, \n",
    "                                                                    print_every=391, name=\"\")    \n",
    "        \n",
    "        student_final, _,__,___  = init_rede(\"Resnet100\")\n",
    "        student_final.load_state_dict(torch.load(\"/home/luigi-doria/IC/Resultado_parciais/student_acc.pth\"))\n",
    "        acc_teste = testa_acuracia(student_final)\n",
    "        torch.save(student.state_dict(), ('/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble {}/{} Redes/Metodo 1/Temp {}/student_acc_{}.pth'.format(data_set,n_redes,temperatures[0],acc_teste)))\n",
    "        #torch.save(student_final.state_dict(), ('/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/{}/Temp {}/student_acc_{}.pth'.format(data_set,i,acc_teste))) TESTE TEMPERATURA\n",
    "\n",
    "        \n",
    "        #print()\n",
    "        #print(\"Student2: \")\n",
    "        #print()\n",
    "        #results_distill[hparam_tuple] = trainStudentOnHparam(teacher_net=teacher, student_net=student2, hparam=hparam, num_epochs=100, \n",
    "        #                                                            train_loader=trainloader, val_loader=None, \n",
    "        #                                                            print_every=391, name=\"2\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upwzKFatm511"
   },
   "outputs": [],
   "source": [
    "for i in range(2,16):\n",
    "    student3 , loss_criterion, optimizer_student3, scheduler_student3  = init_rede(\"Resnet100\")\n",
    "    config = dict (\n",
    "      architecture = \"Resnet18\",\n",
    "      N_ensemble = \"{}\".format(i),\n",
    "      Data_set = \"Cifar 100\",\n",
    "      temperatura = 2,\n",
    "      metodo = \"MSELOSS\",\n",
    "    )\n",
    "\n",
    "    wandb.init(project=\"knowledge distillation Cifar100\", config=config, name=\"Ensemble {}\".format(i), group=\"MSELOSS\")\n",
    "\n",
    "    temperatura = 2\n",
    "\n",
    "    best_acc3 = 0\n",
    "    best_loss3 = 0\n",
    "    best_acc4 = 0\n",
    "    best_loss4 = 0\n",
    "    \n",
    "    n_redes = i\n",
    "    teacher2 = DeepEnsemble(nets[0:n_redes], temperatura=temperatura)\n",
    "    for epoch in range(start_epoch, 100):\n",
    "        #break\n",
    "        print(\"Epoca: \",epoch)\n",
    "        print(\"Student 3: \", end=\" \")\n",
    "        loss_train, acc_train, acc_test, best_acc3, best_loss3 = knowledge_distillation(epoch, aprendiz=student3 , loss_criterion=my_loss, optimizer=optimizer_student3, \n",
    "                                                                                        scheduler=scheduler_student3 ,target=teacher2, temperature=temperatura, best_acc=best_acc3, \n",
    "                                                                                        best_loss=best_loss3, name=\"3\")\n",
    "        #print(\"Student 4: \", end=\" \")\n",
    "        #best_acc4, best_loss4 = knowledge_distillation(epoch, aprendiz=student4 , loss_criterion=my_loss, optimizer=optimizer_student4, \n",
    "        #                                                scheduler=scheduler_student4 ,target=teacher2, temperature=temperatura, best_acc=best_acc4,\n",
    "        #                                                best_loss=best_loss4, name=\"4\")\n",
    "        print()\n",
    "        wandb.log({\"epoch\": epoch, \"loss\": loss_train, \"acuracia treino\": acc_train, \"acuracia teste\": acc_test})\n",
    "\n",
    "\n",
    "    student_final, _,__,___  = init_rede(\"Resnet100\")\n",
    "    student_final.load_state_dict(torch.load(\"/home/luigi-doria/IC/Resultado_parciais/student3_acc.pth\"))\n",
    "    acc_teste = testa_acuracia(student_final)\n",
    "    torch.save(student3.state_dict(), ('/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble {}/{} Redes/Metodo 2/Temp {}/student3_acc_{}.pth'.format(data_set,n_redes,temperatura,acc_teste)))\n",
    "    #torch.save(student_final.state_dict(), ('/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Teste de Temperatura/{}/Temp {}/student3_acc_{}.pth'.format(data_set,i,acc_teste)))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IMrNpZPm511",
    "outputId": "ede5fbbd-11b4-4898-b7a6-38d1fc917744"
   },
   "outputs": [],
   "source": [
    "# Calcula a acuracia da rede\n",
    "\n",
    "student, _,__,___  = init_rede(\"Resnet100\")\n",
    "#student2, _,__,___  = init_rede(\"VGG11\")\n",
    "student3, _,__,___  = init_rede(\"Resnet100\")\n",
    "#student4, _,__,___  = init_rede(\"VGG11\")\n",
    "\n",
    "student.load_state_dict(torch.load(\"/home/luigi-doria/IC/Resultado_parciais/student_acc.pth\"))\n",
    "#student2.load_state_dict(torch.load(\"IC/Resultado_parciais/student2_acc.pth\"))\n",
    "student3.load_state_dict(torch.load(\"/home/luigi-doria/IC/Resultado_parciais/student3_acc.pth\"))\n",
    "#student4.load_state_dict(torch.load(\"IC/Resultado_parciais/student4_acc.pth\"))\n",
    "\n",
    "student.eval()\n",
    "#student2.eval()\n",
    "student3.eval()\n",
    "#student4.eval()\n",
    "\n",
    "correct = 0\n",
    "#correct2 = 0\n",
    "correct3 = 0\n",
    "#correct4 = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    student.eval()\n",
    "#    student2.eval()\n",
    "#    student3.eval()\n",
    "#    student4.eval()\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = student(images)\n",
    "        outputs = outputs.to(\"cpu\")\n",
    "#        outputs2 = student2(images)\n",
    "#        outputs2 = outputs2.to(\"cpu\")\n",
    "        outputs3 = student3(images)\n",
    "        outputs3 = outputs3.to(\"cpu\")\n",
    "#        outputs4 = student4(images)\n",
    "#        outputs4 = outputs4.to(\"cpu\")\n",
    "        \n",
    "        outputs_numpy = outputs.to(\"cpu\").numpy()\n",
    "#       outputs_numpy2 = outputs2.to(\"cpu\").numpy()\n",
    "        outputs_numpy3 = outputs3.to(\"cpu\").numpy()\n",
    "#       outputs_numpy4 = outputs4.to(\"cpu\").numpy()\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#        _, predicted2 = torch.max(outputs2.data, 1)\n",
    "        _, predicted3 = torch.max(outputs3.data, 1)\n",
    "#        _, predicted4 = torch.max(outputs4.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "#        correct2 += (predicted2 == labels).sum().item()\n",
    "        correct3 += (predicted3 == labels).sum().item()\n",
    "#        correct4 += (predicted4 == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f'Accuracy of the Student  on the {len(testloader.dataset)} test images: {round(100 * correct / total,3)} %')\n",
    "#print(f'Accuracy of the Student2 on the {len(testloader.dataset)} test images: {round(100 * correct2 / total,3)} %')\n",
    "print(f'Accuracy of the Student3 on the {len(testloader.dataset)} test images: {round(100 * correct3 / total,3)} %')\n",
    "#print(f'Accuracy of the Student4 on the {len(testloader.dataset)} test images: {round(100 * correct4 / total,3)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNfEUcCPm511"
   },
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), ('/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble {}/{} Redes/Metodo 1/Temp {}/student_acc_{}.pth'.format(data_set,n_redes,temperatures[0],round(100 * correct / total,3))))\n",
    "#torch.save(student2.state_dict(), ('IC/Resultados_Finais/data/student2_acc_{}.pth').format(round(100 * correct2 / total,3)))\n",
    "torch.save(student3.state_dict(), ('/home/luigi-doria/IC/Data_sets/Knowledge_distillation/Ensemble {}/{} Redes/Metodo 2/Temp {}/student3_acc_{}.pth'.format(data_set,n_redes,temperatura,round(100 * correct / total,3))))\n",
    "#torch.save(student4.state_dict(), ('IC/Resultados_Finais/student4_acc_{}.pth').format(round(100 * correct4 / total,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk0Zzjcem512"
   },
   "source": [
    "# Anotaes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACaZXM9hm512"
   },
   "source": [
    "Treinamento:\n",
    "   * Resnet: 93%\n",
    "   * VGG11:  91,36%\n",
    "\n",
    "Descrio:\n",
    "* Student -> Resnet18 usando o metodo de knowledge distilation do artigo\n",
    "* Student2-> Vgg11    usando o metodo de knowledge distilation da internet\n",
    "* Student3-> Resnet18 usando o metodo de knowledge distilation do artigo\n",
    "* Student4-> Vgg11    usando o metodo de knowledge distilation da internet\n",
    "\n",
    "Teacher:\n",
    "   * Ensamble de 15 ResNet18, cada uma das redes tem aproximadamente 93% de acuracia. A acuracia Total do ensamble  95.88%\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "365df4e071874a41a26e9b8db43c1060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39818c11a2cf4477963f0243032c1511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dadb8a25a0694c00b889e0fb1d9ef1f6",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4ad2c93af7a4e22868ec0b38e6dc47a",
      "value": 170498071
     }
    },
    "3fd1a23fdcaa4e61aed97bfedd46ce5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49946b9e2a294d6692e550a699d614c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c0d146e4d054275ac5eae9eb029f1f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d769d9b865f64d6aa2c1d14adc54a816",
       "IPY_MODEL_39818c11a2cf4477963f0243032c1511",
       "IPY_MODEL_b052db7575c74b6190814bbd137b5464"
      ],
      "layout": "IPY_MODEL_3fd1a23fdcaa4e61aed97bfedd46ce5e"
     }
    },
    "b052db7575c74b6190814bbd137b5464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49946b9e2a294d6692e550a699d614c1",
      "placeholder": "",
      "style": "IPY_MODEL_365df4e071874a41a26e9b8db43c1060",
      "value": " 170498071/170498071 [00:03&lt;00:00, 54603965.71it/s]"
     }
    },
    "b4ad2c93af7a4e22868ec0b38e6dc47a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b96b3740fb82456e90e50521d8c2e2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d769d9b865f64d6aa2c1d14adc54a816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e74138fa3ce148c9b0de8e8ec5d5959a",
      "placeholder": "",
      "style": "IPY_MODEL_b96b3740fb82456e90e50521d8c2e2f0",
      "value": "100%"
     }
    },
    "dadb8a25a0694c00b889e0fb1d9ef1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e74138fa3ce148c9b0de8e8ec5d5959a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
